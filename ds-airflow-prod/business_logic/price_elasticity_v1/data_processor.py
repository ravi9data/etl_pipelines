import datetime
import gc
import json
import logging

import pandas as pd

from plugins.utils.s3_utils import (current_path, read_csv_file_s3,
                                    read_excel_file_url, read_file_object_s3,
                                    write_csv_file_s3,
                                    write_parquet_file_to_glue_s3)

logger = logging.getLogger(__name__)


def data_processor(bucket_name,
                   price_data_path,
                   campaign_sku_wo_campaign_id_path,
                   fuel_prices_url,
                   holidays_de_2022_path,
                   holidays_de_2023_path,
                   final_models_path,
                   glue_models_path,
                   price_elasticity_table,
                   price_elasticity_schema):
    """
    This function is used to process the data as mentioned below:
    price_data.csv this file is generated by running the script price_data.sql
        campaign_sku_wo_campaign_id.csv this is generated by extracting the data from campaign files
        Oil_Bulletin_Prices_History.xlsx it has price data for petrol and diesel of eu region
        holidays_de_2022.json holidays_de_2023.json these files have holidays data
        aggregate data based on the period in months

        bfill() - Backfill the data because it was an average of the past week,
        then use ffill() to propagate latest data to current date
        This is why we need to sort on date for the merge and then resort afterwards
    """
    price_data_path = f"s3://{bucket_name}{price_data_path}".format(
        bucket_name=bucket_name, price_data_path=price_data_path
    )
    current_price_data_path = current_path(price_data_path)
    df_main = read_csv_file_s3(current_price_data_path)
    logger.info("Loading price data is completed")

    # adding campaign data
    campaign_sku_wo_campaign_id_path = (
        f"s3://{bucket_name}{campaign_sku_wo_campaign_id_path}".format(
            bucket_name=bucket_name,
            campaign_sku_wo_campaign_id=campaign_sku_wo_campaign_id_path,
        )
    )
    current_campaign_sku_wo_campaign_id_path = current_path(
        campaign_sku_wo_campaign_id_path
    )
    df_campaign = read_csv_file_s3(current_campaign_sku_wo_campaign_id_path)
    df_campaign = df_campaign.drop_duplicates()
    logger.info("Loading Campaign data is completed")

    chunksize = 10000
    results = pd.DataFrame()
    for i in range(0, len(df_main), chunksize):
        df_main_chunk = df_main.iloc[i:i+chunksize]
        df_joined = df_main_chunk.merge(
            df_campaign,
            how="left",
            left_on=["product_sku", "snapshot_date"],
            right_on=["sku", "campaign_date"]
        )
        results = pd.concat([results, df_joined])
    # clean up results
    results.drop(columns=["sku", "campaign_date"], inplace=True)
    results.drop_duplicates(inplace=True)
    results = results.reset_index(drop=True)
    df_main = results.copy()
    del results
    gc.collect()

    logger.info("Merging price data and campaign data is completed")

    df_main.fillna(0, downcast="infer", inplace=True)
    df_main["snapshot_date"] = pd.to_datetime(
        df_main["snapshot_date"], format="%Y-%m-%d"
    )
    logger.info("Date formatting of Merged data is completed")

    # Try adding fuel prices
    df_fuel = read_excel_file_url(fuel_prices_url, "Prices wo taxes, EU", 3, "C:I")
    df_fuel = df_fuel.dropna()
    logger.info("Loading Fuel data is completed")

    df_fuel["Date"] = pd.to_datetime(df_fuel["Date"], format="%Y-%m-%d")
    df_fuel = df_fuel.rename(
        columns={df_fuel.columns[1]: "EU Petrol", df_fuel.columns[2]: "EU Diesel"}
    )
    df_fuel_subset = df_fuel[["Date", "EU Petrol", "EU Diesel"]]
    logger.info("Extracting required columns data from fuel data is completed")

    df_main_2 = (
        pd.merge(
            df_main.sort_values(by=["snapshot_date"]),
            df_fuel_subset,
            left_on="snapshot_date",
            right_on="Date",
            how="left",
        )
        .bfill()
        .ffill()
    )
    logger.info("Merging Main data and fuel data is completed")

    df_main_2 = df_main_2.sort_values(by=["product_sku", "snapshot_date"])
    logger.info("Sorting Merged data is completed")

    # Public holidays
    try:
        holidays_de_2022_data = read_file_object_s3(bucket_name, holidays_de_2022_path)
        holidays_de_2022_data_parsed = json.loads(holidays_de_2022_data)
        holidays_de_2022_dates = holidays_de_2022_data_parsed.values()

        holidays_de_2023_data = read_file_object_s3(bucket_name, holidays_de_2023_path)
        holidays_de_2023_data_parsed = json.loads(holidays_de_2023_data)
        holidays_de_2023_dates = holidays_de_2023_data_parsed.values()
        holidays_de_dt = [
            datetime.datetime.strptime(x, "%Y-%m-%d") for x in holidays_de_2022_dates
        ] + [datetime.datetime.strptime(x, "%Y-%m-%d") for x in holidays_de_2023_dates]
        logger.info("Extracting holidays data is completed")
    except Exception as e:
        print(f"Error reading JSON file: {e}")

    df_main_2["holiday"] = df_main_2["snapshot_date"].apply(
        lambda x: 1 if any(x == y for y in holidays_de_dt) else 0
    )
    logger.info("Matching with holidays data is completed")
    # Sum orders
    df_main_2["total_orders"] = df_main_2[
        [
            "num_orders_m1",
            "num_orders_m3",
            "num_orders_m6",
            "num_orders_m12",
            "num_orders_m18",
            "num_orders_m24",
        ]
    ].sum(axis=1)
    logger.info("Aggregating data based on order period is completed")
    final_models_full_path = f"s3://{bucket_name}{final_models_path}".format(
        bucket_name=bucket_name, final_models_path=final_models_path
    )
    current_final_models_full_path = current_path(final_models_full_path)
    write_csv_file_s3(df_main_2, current_final_models_full_path)

    # Load Final Model into Glue
    df_main_2['Date'] = pd.to_datetime(df_main_2['Date'])
    df_main_2['week'] = df_main_2['Date'].dt.isocalendar().week
    df_main_2.rename(columns={'Date': 'date_col',
                              'month': 'month_col',
                              'day': 'day_col',
                              'views': 'views_col',
                              'EU Petrol': 'eu_petrol',
                              'EU Diesel': 'eu_diesel'}, inplace=True)

    logger.info("Final model is prepared to load into s3 and Glue")
    glue_models_full_path = f"s3://{bucket_name}{glue_models_path}".format(
        bucket_name=bucket_name, glue_models_path=glue_models_path
    )
    write_parquet_file_to_glue_s3(glue_models_full_path,
                                  price_elasticity_table,
                                  price_elasticity_schema,
                                  df_main_2)
    logger.info("Final model loaded to Glue")
    chunk_size = len(df_main_2)
    print("Number of records loaded to Glue is: ", chunk_size)
